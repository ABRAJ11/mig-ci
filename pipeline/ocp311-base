#!groovy

// Set Job properties and triggers
properties([
parameters([string(defaultValue: 'v3.11', description: 'OpenShift version to deploy', name: 'OCP3_VERSION', trim: false), 
// TODO: reset to ci values
credentials(credentialType: 'org.jenkinsci.plugins.plaincredentials.impl.StringCredentialsImpl', defaultValue: 'dgrigore_aws_access_key_id', description: 'EC2 access key ID for auth purposes', name: 'EC2_ACCESS_KEY_ID', required: true),
credentials(credentialType: 'org.jenkinsci.plugins.plaincredentials.impl.StringCredentialsImpl', defaultValue: 'dgrigore_aws_secret_access_key', description: 'EC2 private key needed to access instances, from Jenkins credentials store', name: 'EC2_SECRET_ACCESS_KEY', required: true),
credentials(credentialType: 'org.jenkinsci.plugins.plaincredentials.impl.FileCredentialsImpl', defaultValue: 'dgrigore_ec2_key', description: 'EC2 private key needed to access instances, from Jenkins credentials store', name: 'EC2_PRIV_KEY', required: true),
credentials(credentialType: 'org.jenkinsci.plugins.plaincredentials.impl.StringCredentialsImpl', defaultValue: 'ci_rhel_sub_user', description: 'RHEL Openshift subscription account username', name: 'EC2_SUB_USER', required: true),
credentials(credentialType: 'org.jenkinsci.plugins.plaincredentials.impl.StringCredentialsImpl', defaultValue: 'ci_rhel_sub_pass', description: 'RHEL Openshift subscription account password', name: 'EC2_SUB_PASS', required: true),
string(defaultValue: 'libra', description: 'EC2 SSH key name to deploy on instances for remote access ', name: 'EC2_KEY', trim: false),
string(defaultValue: 'eu-west-1', description: 'EC2 region to deploy instances', name: 'EC2_REGION', trim: false),
string(defaultValue: 'https://github.com/Danil-Grigorev/mig-ci.git', description: 'MIG CI repo URL to checkout', name: 'MIG_CI_REPO', trim: false), // TODO: change to upstream
string(defaultValue: 'oa-to-pipelines', description: 'MIG CI repo branch to checkout', name: 'MIG_CI_BRANCH', trim: false),
booleanParam(defaultValue: true, description: 'EC2 terminate instances after build', name: 'EC2_TERMINATE_INSTANCES')]),
pipelineTriggers([cron('@midnight')])])

// true/false build parameter that defines if we terminate instances once build is done
def EC2_TERMINATE_INSTANCES = params.EC2_TERMINATE_INSTANCES

steps_finished = []

echo "Running job ${env.JOB_NAME}, build ${env.BUILD_ID} on ${env.JENKINS_URL}"
echo "Build URL ${env.BUILD_URL}"
echo "Job URL ${env.JOB_URL}"

node {
    try {
        notifyBuild('STARTED')
        stage('Prepare Build Environment') {
            steps_finished << 'Prepare Build Environment'
            // Prepare EC2 key for ansible consumption
            KEYS_DIR = "${env.WORKSPACE}" + '/keys'
            sh "mkdir -p ${KEYS_DIR}"
            sh "mkdir -p ${env.WORKSPACE}/kubeconfigs"

            KUBECONFIG_TMP = "${env.WORKSPACE}/kubeconfigs/kubeconfig"

            withCredentials([file(credentialsId: "$EC2_PRIV_KEY", variable: "SSH_PRIV_KEY")]) {
                sh "cat ${SSH_PRIV_KEY} > ${KEYS_DIR}/${EC2_KEY}.pem"
                sh "chmod 600 ${KEYS_DIR}/${EC2_KEY}.pem"
            }

            echo 'Cloning ocp-mig-test-data repo'
            checkout([$class: 'GitSCM', branches: [[name: '*/master']], doGenerateSubmoduleConfigurations: false, extensions: [[$class: 'RelativeTargetDirectory', relativeTargetDir: 'ocp-mig-test-data']], submoduleCfg: [], userRemoteConfigs: [[url: 'https://github.com/fusor/ocp-mig-test-data.git']]])

            echo 'Cloning mig-ci repo'
            checkout([$class: 'GitSCM', branches: [[name: "*/$MIG_CI_BRANCH"]], doGenerateSubmoduleConfigurations: false, extensions: [[$class: 'RelativeTargetDirectory', relativeTargetDir: 'mig-ci']], submoduleCfg: [], userRemoteConfigs: [[url: "$MIG_CI_REPO"]]])
        }
    
        stage('Deploy OCP3') {
            steps_finished << 'Deploy OCP3'
            withCredentials([
                    string(credentialsId: "$EC2_ACCESS_KEY_ID", variable: 'AWS_ACCESS_KEY_ID'),
                    string(credentialsId: "$EC2_SECRET_ACCESS_KEY", variable: 'AWS_SECRET_ACCESS_KEY'),
                    string(credentialsId: "$EC2_SUB_USER", variable: 'SUB_USER'),
                    string(credentialsId: "$EC2_SUB_PASS", variable: 'SUB_PASS')
                    ]) 
                {
                    dir('mig-ci') {
                        withEnv(['PATH+EXTRA=~/bin']) {
                            ansiColor('xterm') {
                                ansiblePlaybook(
                                    playbook: 'deploy_ocp3_cluster.yml',
                                    hostKeyChecking: false,
                                    unbuffered: true,
                                    colorized: true)
                            }
                        }
                    }
                }
        }
        
        stage('Load Sample Data/Apps on OCP3') {
            steps_finished << 'Load Sample Data/Apps on OCP3'
            dir('ocp-mig-test-data') {
                withEnv(['PATH+EXTRA=~/bin', "KUBECONFIG=${KUBECONFIG_TMP}", "AWS_REGION=${env.EC2_REGION}"]) {
                    echo "$AWS_REGION"
                    ansiColor('xterm') {
                        ansiblePlaybook(
                            playbook: 'nginx.yml',
                            extras: '-e "with_backup=false" -e "with_restore=false"',
                            hostKeyChecking: false,
                            unbuffered: true,
                            colorized: true)
                    }
                }
            }
        }
        
       stage('Run OCP3 Router Sanity Checks') {
            steps_finished << 'Run OCP3 Router Sanity Checks'
            dir('mig-ci') {
                withEnv(['PATH+EXTRA=~/bin', "KUBECONFIG=${KUBECONFIG_TMP}", "AWS_REGION=${env.EC2_REGION}"]) {
                    echo "$AWS_REGION"
                    ansiColor('xterm') {
                        ansiblePlaybook(
                            playbook: 'ocp_sanity_check.yml',
                            tags: 'router',
                            hostKeyChecking: false,
                            unbuffered: true,
                            colorized: true)
                    }
                }
            }
        } 
        stage('Run OCP3 Sanity Checks') {
            steps_finished << 'Run OCP3 Sanity Checks'
            dir('mig-ci') {
                withEnv(['PATH+EXTRA=~/bin', "KUBECONFIG=${KUBECONFIG_TMP}", "AWS_REGION=${env.EC2_REGION}"]) {
                    echo "$AWS_REGION"
                    ansiColor('xterm') {
                        ansiblePlaybook(
                            playbook: 'ocp_sanity_check.yml',
                            tags: 'nginx',
                            hostKeyChecking: false,
                            unbuffered: true,
                            colorized: true)
                    }
                }
            }
        }
    } catch (e) {
        currentBuild.result = "FAILED"
        throw e
    } finally {
        // Success or failure, always send notifications
        notifyBuild(currentBuild.result)
        stage('Clean Up Environment') {
            if (EC2_TERMINATE_INSTANCES) {
                withCredentials([
                    string(credentialsId: "$EC2_ACCESS_KEY_ID", variable: 'AWS_ACCESS_KEY_ID'),
                    string(credentialsId: "$EC2_SECRET_ACCESS_KEY", variable: 'AWS_SECRET_ACCESS_KEY'),
                    ])
                {
                    dir('mig-ci') {
                        withEnv(['PATH+EXTRA=~/bin', "AWS_REGION=${env.EC2_REGION}"]) {
                            echo "$AWS_REGION"
                            ansiColor('xterm') {
                                ansiblePlaybook(
                                    playbook: 'destroy_ocp3_cluster.yml',
                                    hostKeyChecking: false,
                                    unbuffered: true,
                                    colorized: true)
                            }
                        }
                    }
                }
            }
            cleanWs cleanWhenFailure: false, notFailBuild: true
        }
    }
}

def notifyBuild(String buildStatus = 'STARTED') {
  // build status of null means successful
  buildStatus =  buildStatus ?: 'SUCCESSFUL'
 
  // Default values
  def colorName = 'RED'
  def colorCode = '#FF0000'
  def subject = "${buildStatus}: Job '${env.JOB_NAME}, build [${env.BUILD_NUMBER}]'"
  def summary = "${subject}\nLink: (${env.BUILD_URL})\n"

  // Override default values based on build status
  if (buildStatus == 'STARTED') {
    colorCode = '#FFFF00'
  } else if (buildStatus == 'SUCCESSFUL') {
    colorCode = '#00FF00'
    summary = summary + steps_finished.join(' - SUCCESS\n')
    summary = summary + ' - SUCCESS\n'
  } else {
    colorCode = '#FF0000'
    summary = summary + steps_finished.join(' - SUCCESS\n')
    summary = summary + ' - FAILED\n'
  }
 
  // Send notifications
  slackSend (color: colorCode, message: summary)
}
